{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Training Throughput Benchmark (run in Colab or Locally)\n",
    "\n",
    "Measures synthetic training throughput (images/sec) for small CNNs in PyTorch and TensorFlow. Avoids disk I/O to focuse on compute performance.\n",
    "\n",
    "- Mixed precision AMP for NVIDIA GPUs\n",
    "- Increase `BATCH_SIZE` or switch to `resnet50` for a heavier test\n",
    "- Dependencies: pip install -q torch torchvision tensorflow tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config => USE_GPU=True, PRECISION=fp32, BATCH_SIZE=64, IMAGE_SIZE=224, ITERS=100, WARMUP=20, MODEL=resnet18\n"
     ]
    }
   ],
   "source": [
    "USE_GPU      = True       # Set False to force CPU even if CUDA is available\n",
    "PRECISION    = \"fp32\"      # \"fp32\" | \"amp\" (CUDA mixed precision) | \"bf16\" (if supported)\n",
    "BATCH_SIZE   = 64\n",
    "IMAGE_SIZE   = 224\n",
    "ITERS        = 200        # Timed iterations\n",
    "WARMUP       = 10         # Warmup iterations (not timed)\n",
    "MODEL_NAME   = \"resnet18\" # \"resnet18\" (fast) or \"resnet50\" (heavier)\n",
    "print(f\"Config => USE_GPU={USE_GPU}, PRECISION={PRECISION}, BATCH_SIZE={BATCH_SIZE}, \"\n",
    "      f\"IMAGE_SIZE={IMAGE_SIZE}, ITERS={ITERS}, WARMUP={WARMUP}, MODEL={MODEL_NAME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MyGithub\\ML_PyTorch_Experiments\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jari\\AppData\\Local\\Temp\\ipykernel_60912\\695088926.py:73: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler   = torch.cuda.amp.GradScaler(enabled=use_amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warmup: 20 iters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:45<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timed run: 100 iters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:24<03:41,  2.46s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 101\u001b[0m\n\u001b[0;32m     99\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m progress_iter(ITERS, ITERS):\n\u001b[1;32m--> 101\u001b[0m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    103\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39msynchronize()\n",
      "Cell \u001b[1;32mIn[2], line 88\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m()\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     out \u001b[38;5;241m=\u001b[39m model(x); loss \u001b[38;5;241m=\u001b[39m criterion(out, y)\n\u001b[1;32m---> 88\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m; optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\MyGithub\\ML_PyTorch_Experiments\\.venv\\Lib\\site-packages\\torch\\_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    639\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    640\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    645\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    646\u001b[0m     )\n\u001b[1;32m--> 647\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\MyGithub\\ML_PyTorch_Experiments\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\MyGithub\\ML_PyTorch_Experiments\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:829\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    827\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time, os, math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Try to provide a progress bar; fall back to prints if tqdm not installed\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "    def progress_iter(it, total):\n",
    "        return tqdm(range(it), total=total)\n",
    "except Exception:\n",
    "    def progress_iter(it, total):\n",
    "        class Dummy:\n",
    "            def __init__(self, it): self.it = it\n",
    "            def __iter__(self):\n",
    "                for i in range(self.it):\n",
    "                    if i % max(1, self.it // 10) == 0:\n",
    "                        print(f\"Progress: {i}/{self.it}\")\n",
    "                    yield i\n",
    "        return Dummy(it)\n",
    "\n",
    "def get_device(use_gpu: bool) -> str:\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    return \"cpu\"\n",
    "\n",
    "def make_model(name=\"resnet18\", num_classes=1000):\n",
    "    try:\n",
    "        from torchvision.models import resnet18, resnet50\n",
    "        if name == \"resnet18\":\n",
    "            return resnet18(num_classes=num_classes)\n",
    "        elif name == \"resnet50\":\n",
    "            return resnet50(num_classes=num_classes)\n",
    "        else:\n",
    "            raise ValueError(\"Supported: resnet18, resnet50\")\n",
    "    except Exception:\n",
    "        # Fallback tiny CNN if torchvision isn’t available\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 1000),\n",
    "        )\n",
    "\n",
    "device = get_device(USE_GPU)\n",
    "print(\"Device:\", device)\n",
    "if device == \"cuda\":\n",
    "    p = torch.cuda.get_device_properties(0)\n",
    "    print(f\"GPU: {p.name} | VRAM: {p.total_memory/1024**3:.1f} GB | CC: {p.major}.{p.minor}\")\n",
    "\n",
    "torch.backends.cudnn.benchmark = True  # speedup for fixed shapes\n",
    "\n",
    "# Model / loss / opt\n",
    "model = make_model(MODEL_NAME).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "# Channels-last helps CNNs on CUDA, esp. with AMP/BF16\n",
    "if device == \"cuda\" and PRECISION in (\"amp\", \"bf16\"):\n",
    "    model = model.to(memory_format=torch.channels_last)\n",
    "\n",
    "# Synthetic batch\n",
    "N, C, H, W = BATCH_SIZE, 3, IMAGE_SIZE, IMAGE_SIZE\n",
    "x = torch.randn(N, C, H, W, device=device)\n",
    "y = torch.randint(0, 1000, (N,), device=device)\n",
    "if device == \"cuda\" and PRECISION in (\"amp\", \"bf16\"):\n",
    "    x = x.to(memory_format=torch.channels_last)\n",
    "\n",
    "# Precision helpers\n",
    "use_amp  = (device == \"cuda\" and PRECISION == \"amp\")\n",
    "use_bf16 = (device == \"cuda\" and PRECISION == \"bf16\")\n",
    "scaler   = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "bf16_ctx = torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16) if use_bf16 else None\n",
    "\n",
    "def train_step():\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    if use_amp:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            out = model(x); loss = criterion(out, y)\n",
    "        scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n",
    "    elif use_bf16:\n",
    "        with bf16_ctx:\n",
    "            out = model(x); loss = criterion(out, y)\n",
    "        loss.backward(); optimizer.step()\n",
    "    else:\n",
    "        out = model(x); loss = criterion(out, y)\n",
    "        loss.backward(); optimizer.step()\n",
    "\n",
    "# Warmup (with a tiny progress signal)\n",
    "print(f\"Warmup: {WARMUP} iters...\")\n",
    "for i in progress_iter(WARMUP, WARMUP):\n",
    "    train_step()\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "# Timed section (with progress bar)\n",
    "print(f\"Timed run: {ITERS} iters...\")\n",
    "t0 = time.perf_counter()\n",
    "for _ in progress_iter(ITERS, ITERS):\n",
    "    train_step()\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "dt = time.perf_counter() - t0\n",
    "\n",
    "imgs = ITERS * BATCH_SIZE\n",
    "ips  = imgs / dt\n",
    "print(\"\\n=== PYTORCH RESULTS ===\")\n",
    "print(f\"Device: {device} | Precision: {PRECISION}\")\n",
    "print(f\"Model: {MODEL_NAME} | Batch: {BATCH_SIZE} | Image: {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",
    "print(f\"Iters: {ITERS} (warmup {WARMUP}) | Time: {dt:.3f}s\")\n",
    "print(f\"Throughput: {ips:,.1f} images/sec  (synthetic data)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import mixed_precision\n",
    "    tf_ok = True\n",
    "except Exception as e:\n",
    "    tf_ok = False\n",
    "    print(\"TensorFlow not available; install tensorflow to run this cell.\")\n",
    "\n",
    "if tf_ok:\n",
    "    # Device selection: if USE_GPU False or no GPU, force CPU\n",
    "    dev_name = \"/GPU:0\" if (USE_GPU and len(tf.config.list_physical_devices('GPU'))>0) else \"/CPU:0\"\n",
    "    print(\"TF device:\", dev_name)\n",
    "\n",
    "    # Mixed precision policy (only meaningful on GPU)\n",
    "    if \"GPU\" in dev_name and PRECISION in (\"amp\", \"bf16\"):\n",
    "        policy = \"mixed_bfloat16\" if PRECISION==\"bf16\" else \"mixed_float16\"\n",
    "        try:\n",
    "            mixed_precision.set_global_policy(policy)\n",
    "            print(\"TF mixed precision:\", policy)\n",
    "        except Exception as e:\n",
    "            print(\"Could not set mixed precision:\", e)\n",
    "\n",
    "    # Simple Keras model (ResNet50) if available; fallback to small CNN\n",
    "    try:\n",
    "        model = tf.keras.applications.ResNet50(weights=None, classes=1000)\n",
    "        model_name = \"ResNet50\"\n",
    "    except Exception:\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(32, 3, strides=2, padding='same', activation='relu', input_shape=(IMAGE_SIZE,IMAGE_SIZE,3)),\n",
    "            tf.keras.layers.Conv2D(64, 3, strides=2, padding='same', activation='relu'),\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Dense(1000)\n",
    "        ])\n",
    "        model_name = \"TinyCNN\"\n",
    "\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "\n",
    "    # Synthetic inputs\n",
    "    x = tf.random.normal([BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 3])\n",
    "    y = tf.random.uniform([BATCH_SIZE], maxval=1000, dtype=tf.int32)\n",
    "\n",
    "    # Warmup with progress\n",
    "    print(f\"Warmup: {WARMUP} iters...\")\n",
    "    for i in range(WARMUP):\n",
    "        model.train_on_batch(x, y)\n",
    "        if (i+1) % max(1, WARMUP//10) == 0:\n",
    "            print(f\"Warmup progress: {i+1}/{WARMUP}\")\n",
    "\n",
    "    # Timed with progress\n",
    "    print(f\"Timed run: {ITERS} iters...\")\n",
    "    t0 = time.perf_counter()\n",
    "    for i in range(ITERS):\n",
    "        model.train_on_batch(x, y)\n",
    "        if (i+1) % max(1, ITERS//10) == 0:\n",
    "            print(f\"Run progress: {i+1}/{ITERS}\")\n",
    "    dt = time.perf_counter() - t0\n",
    "\n",
    "    ips = (ITERS * BATCH_SIZE) / dt\n",
    "    print(\"\\n=== TENSORFLOW RESULTS ===\")\n",
    "    print(f\"Device: {dev_name} | Precision: {PRECISION}\")\n",
    "    print(f\"Model: {model_name} | Batch: {BATCH_SIZE} | Image: {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",
    "    print(f\"Iters: {ITERS} (warmup {WARMUP}) | Time: {dt:.3f}s\")\n",
    "    print(f\"Throughput: {ips:,.1f} images/sec  (synthetic data)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
