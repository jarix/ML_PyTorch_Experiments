{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Training Throughput Benchmark (run in Colab or Locally)\n",
    "\n",
    "Measures synthetic training throughput (images/sec) for small CNNs in PyTorch and TensorFlow. Avoids disk I/O to focuse on compute performance.\n",
    "\n",
    "- Mixed precision AMP for NVIDIA GPUs\n",
    "- Increase `BATCH_SIZE` or switch to `resnet50` for a heavier test\n",
    "- Dependencies: pip install -q torch torchvision tensorflow tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90c932b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config => USE_GPU=True, PRECISION=fp32, BATCH_SIZE=64, IMAGE_SIZE=224, ITERS=200, WARMUP=10, MODEL=resnet50\n"
     ]
    }
   ],
   "source": [
    "USE_GPU      = True       # Set False to force CPU even if CUDA is available\n",
    "PRECISION    = \"fp32\"      # \"fp32\" | \"amp\" (CUDA mixed precision) | \"bf16\" (if supported)\n",
    "BATCH_SIZE   = 64\n",
    "IMAGE_SIZE   = 224\n",
    "ITERS        = 200        # Timed iterations\n",
    "WARMUP       = 10         # Warmup iterations (not timed)\n",
    "MODEL_NAME   = \"resnet50\" # \"resnet18\" (fast) or \"resnet50\" (heavier)\n",
    "print(f\"Config => USE_GPU={USE_GPU}, PRECISION={PRECISION}, BATCH_SIZE={BATCH_SIZE}, \"\n",
    "      f\"IMAGE_SIZE={IMAGE_SIZE}, ITERS={ITERS}, WARMUP={WARMUP}, MODEL={MODEL_NAME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be82c04d",
   "metadata": {},
   "source": [
    "## PyTorch benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39ba23ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jari/MyGithub/ML_PyTorch_Experiments/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/jari/MyGithub/ML_PyTorch_Experiments/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA GB10 | VRAM: 119.6 GB | CC: 12.1\n",
      "Using model: resnet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59720/1973414970.py:76: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler   = torch.cuda.amp.GradScaler(enabled=use_amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warmup: 10 iters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timed run: 200 iters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:15<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PYTORCH RESULTS ===\n",
      "Device: cuda | Precision: fp32\n",
      "Model: resnet50 | Batch: 64 | Image: 224x224\n",
      "Iters: 200 (warmup 10) | Time: 76.183s\n",
      "Throughput: 168.0 images/sec  (synthetic data)\n"
     ]
    }
   ],
   "source": [
    "import time, os, math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Try to provide a progress bar; fall back to prints if tqdm not installed\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "    def progress_iter(it, total):\n",
    "        return tqdm(range(it), total=total)\n",
    "except Exception:\n",
    "    def progress_iter(it, total):\n",
    "        class Dummy:\n",
    "            def __init__(self, it): self.it = it\n",
    "            def __iter__(self):\n",
    "                for i in range(self.it):\n",
    "                    if i % max(1, self.it // 10) == 0:\n",
    "                        print(f\"Progress: {i}/{self.it}\")\n",
    "                    yield i\n",
    "        return Dummy(it)\n",
    "\n",
    "def get_device(use_gpu: bool) -> str:\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    return \"cpu\"\n",
    "\n",
    "def make_model(name=\"resnet18\", num_classes=1000):\n",
    "    try:\n",
    "        from torchvision.models import resnet18, resnet50\n",
    "        if name == \"resnet18\":\n",
    "            print(f\"Using model: {name}\")\n",
    "            return resnet18(num_classes=num_classes)\n",
    "        elif name == \"resnet50\":\n",
    "            print(f\"Using model: {name}\")\n",
    "            return resnet50(num_classes=num_classes)\n",
    "        else:\n",
    "            raise ValueError(\"Supported: resnet18, resnet50\")\n",
    "    except Exception:\n",
    "        # Fallback tiny CNN if torchvision isn’t available\n",
    "        print(\"Using model: Small Dummy\")\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 1000),\n",
    "        )\n",
    "\n",
    "device = get_device(USE_GPU)\n",
    "print(\"Device:\", device)\n",
    "if device == \"cuda\":\n",
    "    p = torch.cuda.get_device_properties(0)\n",
    "    print(f\"GPU: {p.name} | VRAM: {p.total_memory/1024**3:.1f} GB | CC: {p.major}.{p.minor}\")\n",
    "\n",
    "torch.backends.cudnn.benchmark = True  # speedup for fixed shapes\n",
    "\n",
    "# Model / loss / opt\n",
    "model = make_model(MODEL_NAME).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "# Channels-last helps CNNs on CUDA, esp. with AMP/BF16\n",
    "if device == \"cuda\" and PRECISION in (\"amp\", \"bf16\"):\n",
    "    model = model.to(memory_format=torch.channels_last)\n",
    "\n",
    "# Synthetic batch\n",
    "N, C, H, W = BATCH_SIZE, 3, IMAGE_SIZE, IMAGE_SIZE\n",
    "x = torch.randn(N, C, H, W, device=device)\n",
    "y = torch.randint(0, 1000, (N,), device=device)\n",
    "if device == \"cuda\" and PRECISION in (\"amp\", \"bf16\"):\n",
    "    x = x.to(memory_format=torch.channels_last)\n",
    "\n",
    "# Precision helpers\n",
    "use_amp  = (device == \"cuda\" and PRECISION == \"amp\")\n",
    "use_bf16 = (device == \"cuda\" and PRECISION == \"bf16\")\n",
    "scaler   = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "bf16_ctx = torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16) if use_bf16 else None\n",
    "\n",
    "def train_step():\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    if use_amp:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            out = model(x); loss = criterion(out, y)\n",
    "        scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n",
    "    elif use_bf16:\n",
    "        with bf16_ctx:\n",
    "            out = model(x); loss = criterion(out, y)\n",
    "        loss.backward(); optimizer.step()\n",
    "    else:\n",
    "        out = model(x); loss = criterion(out, y)\n",
    "        loss.backward(); optimizer.step()\n",
    "\n",
    "# Warmup (with a tiny progress signal)\n",
    "print(f\"Warmup: {WARMUP} iters...\")\n",
    "for i in progress_iter(WARMUP, WARMUP):\n",
    "    train_step()\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "# Timed section (with progress bar)\n",
    "print(f\"Timed run: {ITERS} iters...\")\n",
    "t0 = time.perf_counter()\n",
    "for _ in progress_iter(ITERS, ITERS):\n",
    "    train_step()\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "dt = time.perf_counter() - t0\n",
    "\n",
    "imgs = ITERS * BATCH_SIZE\n",
    "ips  = imgs / dt\n",
    "print(\"\\n=== PYTORCH RESULTS ===\")\n",
    "print(f\"Device: {device} | Precision: {PRECISION}\")\n",
    "print(f\"Model: {MODEL_NAME} | Batch: {BATCH_SIZE} | Image: {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",
    "print(f\"Iters: {ITERS} (warmup {WARMUP}) | Time: {dt:.3f}s\")\n",
    "print(f\"Throughput: {ips:,.1f} images/sec  (synthetic data)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import mixed_precision\n",
    "    tf_ok = True\n",
    "except Exception as e:\n",
    "    tf_ok = False\n",
    "    print(\"TensorFlow not available; install tensorflow to run this cell.\")\n",
    "\n",
    "if tf_ok:\n",
    "    # Device selection: if USE_GPU False or no GPU, force CPU\n",
    "    dev_name = \"/GPU:0\" if (USE_GPU and len(tf.config.list_physical_devices('GPU'))>0) else \"/CPU:0\"\n",
    "    print(\"TF device:\", dev_name)\n",
    "\n",
    "    # Mixed precision policy (only meaningful on GPU)\n",
    "    if \"GPU\" in dev_name and PRECISION in (\"amp\", \"bf16\"):\n",
    "        policy = \"mixed_bfloat16\" if PRECISION==\"bf16\" else \"mixed_float16\"\n",
    "        try:\n",
    "            mixed_precision.set_global_policy(policy)\n",
    "            print(\"TF mixed precision:\", policy)\n",
    "        except Exception as e:\n",
    "            print(\"Could not set mixed precision:\", e)\n",
    "\n",
    "    # Simple Keras model (ResNet50) if available; fallback to small CNN\n",
    "    try:\n",
    "        model = tf.keras.applications.ResNet50(weights=None, classes=1000)\n",
    "        model_name = \"ResNet50\"\n",
    "    except Exception:\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(32, 3, strides=2, padding='same', activation='relu', input_shape=(IMAGE_SIZE,IMAGE_SIZE,3)),\n",
    "            tf.keras.layers.Conv2D(64, 3, strides=2, padding='same', activation='relu'),\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Dense(1000)\n",
    "        ])\n",
    "        model_name = \"TinyCNN\"\n",
    "\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "\n",
    "    # Synthetic inputs\n",
    "    x = tf.random.normal([BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 3])\n",
    "    y = tf.random.uniform([BATCH_SIZE], maxval=1000, dtype=tf.int32)\n",
    "\n",
    "    # Warmup with progress\n",
    "    print(f\"Warmup: {WARMUP} iters...\")\n",
    "    for i in range(WARMUP):\n",
    "        model.train_on_batch(x, y)\n",
    "        if (i+1) % max(1, WARMUP//10) == 0:\n",
    "            print(f\"Warmup progress: {i+1}/{WARMUP}\")\n",
    "\n",
    "    # Timed with progress\n",
    "    print(f\"Timed run: {ITERS} iters...\")\n",
    "    t0 = time.perf_counter()\n",
    "    for i in range(ITERS):\n",
    "        model.train_on_batch(x, y)\n",
    "        if (i+1) % max(1, ITERS//10) == 0:\n",
    "            print(f\"Run progress: {i+1}/{ITERS}\")\n",
    "    dt = time.perf_counter() - t0\n",
    "\n",
    "    ips = (ITERS * BATCH_SIZE) / dt\n",
    "    print(\"\\n=== TENSORFLOW RESULTS ===\")\n",
    "    print(f\"Device: {dev_name} | Precision: {PRECISION}\")\n",
    "    print(f\"Model: {model_name} | Batch: {BATCH_SIZE} | Image: {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",
    "    print(f\"Iters: {ITERS} (warmup {WARMUP}) | Time: {dt:.3f}s\")\n",
    "    print(f\"Throughput: {ips:,.1f} images/sec  (synthetic data)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
